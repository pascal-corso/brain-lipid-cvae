{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MALDI Data Preprocessing for c-VAE\n",
    "\n",
    "This notebook demonstrates the preprocessing pipeline for MALDI mass spectrometry imaging data before training the conditional VAE model.\n",
    "\n",
    "## Preprocessing Pipeline Overview:\n",
    "1. Load raw MALDI data and coordinates\n",
    "2. Process, clean and normalise MALDI data\n",
    "3. Transform coordinate system\n",
    "4. Augment data by creating samples with additional noise\n",
    "5. Zero out indices in the samples (input matrix)\n",
    "6. Visualise processed data\n",
    "7. Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('/home/pasco/sdsc_mlibra/JupyterNotebooks/cleaned/brain_lipid_cvae_pcorso') # Replace with the path where you git-cloned the repo\n",
    "# Import the preprocessing modules\n",
    "from utils.dataprocessing import MALDIPreprocessor, CoordinateTransformer, DataGenerator, process_maldi_data\n",
    "from utils.visualisation import ReconstructionVisualizer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load raw data\n",
    "\n",
    "First, we will load the raw MALDI data as a Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Parquet file with original MALDI-MSI data using pandas\n",
    "data_dir = Path(\"data\")\n",
    "df = pd.read_parquet(data_dir / 'lba_all_pixels_fully_abamapped11282023_exp_lipidclasses_allenannot_train.parquet')\n",
    "print(df.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Zeroing out coordinates at defined indices for testing set and remove zero values from original MALDI data\n",
    "\n",
    "Choose the lipid to reconstruct and apply amputation operation before training to exclude testing set points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, coords_trunc, ref_data, lipid_data, sections, indices_null, indices_zeros = process_maldi_data(df, 'SM 42:2', step=10, exclude_sections=[list(range(1, 30, 2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coordinate transformation\n",
    "\n",
    "Transform coordinates between Cartesian and spherical coordinate systems for amputated and complete coordinate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize coordinate transformer\n",
    "coord_transformer = CoordinateTransformer()\n",
    "\n",
    "# Transform to spherical coordinates\n",
    "x, y, z = coords_trunc\n",
    "xx, yy, zz = coords\n",
    "r, theta, phi = coord_transformer.cartesian_to_spherical(\n",
    "    x, y, z,\n",
    "    center_x=(max(x)+min(x))/2,\n",
    "    center_y=(max(y)+min(y))/2,\n",
    "    center_z=(max(z)+min(z))/2\n",
    ")\n",
    "rC, thetaC, phiC = coord_transformer.cartesian_to_spherical(\n",
    "    xx, yy, zz,\n",
    "    center_x=(max(xx)+min(xx))/2,\n",
    "    center_y=(max(yy)+min(yy))/2,\n",
    "    center_z=(max(zz)+min(zz))/2\n",
    ")\n",
    "\n",
    "# Stack spherical coordinates\n",
    "coords_spherical = np.vstack((r, theta, phi))\n",
    "coords_complete_spherical = np.vstack((rC, thetaC, phiC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Noised data sample generation\n",
    "\n",
    "Generate training samples using data augmentation through noise addition to the reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise data generator\n",
    "data_generator = DataGenerator(\n",
    "    original_data=ref_data,\n",
    "    num_samples=2000,\n",
    "    noise_type='mixed'\n",
    ")\n",
    "\n",
    "# Generate augmented samples\n",
    "maldi_samples = data_generator.generate_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Zeroing out the generated noised data using the previous indices \n",
    "\n",
    "Apply preprocessing steps to prepare the data for the c-VAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amputated MALDI input matrix\n",
    "maldi_processed = maldi_samples.copy()\n",
    "maldi_processed[:,indices_null] = 0\n",
    "\n",
    "logger.info(f\"Spherical coordinates shape: {coords_spherical.shape}\")\n",
    "logger.info(f\"Spherical non zeroed-out coordinates shape: {coords_complete_spherical.shape}\")\n",
    "logger.info(f\"Cartesian coordinates shape: {coords_trunc.shape}\")\n",
    "logger.info(f\"Cartesian non zeroed-out coordinates shape: {coords.shape}\")\n",
    "logger.info(f\"Processed MALDI input matrix shape: {maldi_processed.shape}\")\n",
    "logger.info(f\"Augmented non-zeroed out samples shape: {maldi_samples.shape}\")\n",
    "logger.info(f\"Reference data array shape: {ref_data.shape}\")\n",
    "logger.info(f\"Original lipid data array shape: {lipid_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualise processed data\n",
    "\n",
    "Create visualisations to verify the preprocessing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialise visualizer\n",
    "visualizer = ReconstructionVisualizer()\n",
    "\n",
    "# Plot spatial distribution\n",
    "visualizer.plot_spatial_distribution(\n",
    "    values=ref_data,  \n",
    "    coordinates=coords,\n",
    "    title='Spatial Distribution - Reference Data',\n",
    "    save_path='spatial_distribution.png'\n",
    ")\n",
    "\n",
    "# Plot spatial distribution\n",
    "visualizer.plot_spatial_distribution(\n",
    "    values=maldi_samples[500,:],  \n",
    "    coordinates=coords,\n",
    "    title='Spatial Distribution - Generated Sample',\n",
    "    save_path='spatial_distribution_generatedSample.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histograms\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create histogram with specific number of bins\n",
    "#n_bins = 50  # you can adjust this\n",
    "bin_width = 0.01  # Replace with your desired width\n",
    "bins = np.arange(-0.05, 1 + bin_width, bin_width)\n",
    "ax.hist(ref_data, bins=bins, density=True, alpha=0.7, color='blue', \n",
    "        edgecolor='black', label='Data')\n",
    "ax.set_ylim(0, 35)\n",
    "ax.set_xlim(-0.05, 1)\n",
    "\n",
    "# Add mean and std lines\n",
    "mean = np.mean(ref_data)\n",
    "std = np.std(ref_data)\n",
    "ax.axvline(mean, color='red', linestyle='--', label=f'Mean: {mean:.2f}')\n",
    "ax.axvline(mean + std, color='green', linestyle=':', label=f'±1 Std: {std:.2f}')\n",
    "ax.axvline(mean - std, color='green', linestyle=':')\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Histogram of Reference Data')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('spatial_distribution_hist.png', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create histogram with specific number of bins\n",
    "#n_bins = 50  # you can adjust this\n",
    "bin_width = 0.01  # Replace with your desired width\n",
    "bins = np.arange(-0.05, 1 + bin_width, bin_width)\n",
    "ax.hist(maldi_samples[1500,:], bins=bins, density=True, alpha=0.7, color='blue', \n",
    "        edgecolor='black', label='Data')\n",
    "ax.set_ylim(0, 35)\n",
    "ax.set_xlim(-0.05, 1)\n",
    "# Add mean and std lines\n",
    "mean = np.mean(maldi_samples[500,:])\n",
    "std = np.std(maldi_samples[500,:])\n",
    "ax.axvline(mean, color='red', linestyle='--', label=f'Mean: {mean:.2f}')\n",
    "ax.axvline(mean + std, color='green', linestyle=':', label=f'±1 Std: {std:.2f}')\n",
    "ax.axvline(mean - std, color='green', linestyle=':')\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Histogram of Generated Sample Data')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('spatial_distribution_generatedSample_hist.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save processed data\n",
    "\n",
    "Save the preprocessed data for training the CVAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_h5_data(data_dict, output_dir):\n",
    "    \"\"\"Save processed data to H5 files.\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for name, data in data_dict.items():\n",
    "        with h5py.File(output_dir / f\"{name}.h5\", 'w') as f:\n",
    "            f.create_dataset('data', data=data, compression='gzip')\n",
    "        logger.info(f\"Saved {name} to {output_dir / f'{name}.h5'}\")\n",
    "\n",
    "# Prepare data dictionary\n",
    "processed_data = {\n",
    "    'maldi_processed': maldi_processed, # To use as input matrix for training\n",
    "    'coords_complete': coords_complete_spherical, # To use as conditioning for inference\n",
    "    'coords_spherical': coords_spherical, # To use as conditioning for training\n",
    "    'coords_cart_complete': coords, # To visualise the spatial distribution after inference\n",
    "    'reference_data': ref_data, # To use to compute loss for training\n",
    "    'maldi_samples': maldi_samples, # To check noised samples generated\n",
    "    'indices_zeroedout': indices_null # To amputate the coordinates during inference\n",
    "}\n",
    "\n",
    "# Save all processed data\n",
    "save_h5_data(processed_data, 'data/H5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Preprocessing steps completed:\n",
    "1. ✓ Load raw MALDI data and coordinates\n",
    "2. ✓ Process, clean and normalise MALDI data\n",
    "3. ✓ Transform coordinate system\n",
    "4. ✓ Augment data by creating samples with additional noise\n",
    "5. ✓ Zero out indices in the samples (input matrix)\n",
    "6. ✓ Visualise processed data\n",
    "7. ✓ Save processed data\n",
    "\n",
    "The processed data is now ready for training the c-VAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
