{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c-VAE Model Training for MALDI Data\n",
    "\n",
    "This notebook demonstrates the training process for the Conditional Variational Autoencoder (c-VAE) on MALDI mass spectrometry imaging data.\n",
    "\n",
    "## Training Pipeline Overview:\n",
    "1. Configure model hyperparameters\n",
    "2. Load preprocessed data\n",
    "3. Initialise model and optimiser\n",
    "4. Train and save the model\n",
    "5. Analyse the learned latent space\n",
    "6. Save model's configuration and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "os.chdir('/home/pasco/sdsc_mlibra/JupyterNotebooks/cleaned/brain_lipid_cvae_pcorso') # Replace with the path where you git-cloned the repo\n",
    "\n",
    "# Import our modules\n",
    "from models.cvae import ConditionalVAE\n",
    "from utils.dataloader import MALDIDataset, create_dataloader\n",
    "from utils.visualisation import TrainingVisualizer, ReconstructionVisualizer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set up model hyperparameters and training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "config = {\n",
    "    'hidden_dim': 512,      # Dimension of hidden layers\n",
    "    'latent_dim': 256,      # Dimension of latent space\n",
    "    'beta': 0.1,            # Weight of KL divergence term\n",
    "    'batch_size': 128,      # Batch size for training\n",
    "    'learning_rate': 5e-4,  # Learning rate\n",
    "    'weight_decay': 0.01,   # Weight decay for regularization\n",
    "    'dropout_rate': 0.1,    # Dropout rate\n",
    "    'epochs': 60,           # Number of training epochs\n",
    "    'device': 'cpu'         # 'cpu', 'cuda' (if NVIDIA GPU available) or 'mps' if Apple Silicon CPU/GPU\n",
    "}\n",
    "\n",
    "logger.info(f\"Using device: {config['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "\n",
    "Load the preprocessed data and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs available and whether GPU computation is possible:  20 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processed rows 0 to 500 of 2000\n",
      "INFO:root:Processed rows 500 to 1000 of 2000\n",
      "INFO:root:Processed rows 1000 to 1500 of 2000\n",
      "INFO:root:Processed rows 1500 to 2000 of 2000\n",
      "INFO:root:Number of points: 47968\n",
      "INFO:root:Matrix shape: (47968,)\n",
      "INFO:root:Matrix data type: float64\n",
      "INFO:root:Dataset initialized with shapes:\n",
      "INFO:root:MALDI shape: torch.Size([2000, 47968])\n",
      "INFO:root:CCF shape: torch.Size([3, 47968])\n",
      "INFO:root:Reference data shape: torch.Size([1, 47968])\n",
      "INFO:__main__:Number of spatial points: 47968\n",
      "INFO:__main__:Coordinate dimensions: 3\n"
     ]
    }
   ],
   "source": [
    "# Set data paths\n",
    "data_dir = Path('data/H5')\n",
    "maldi_path = data_dir / 'maldi_processed.h5'\n",
    "coords_path = data_dir / 'coords_spherical.h5'\n",
    "ref_path = data_dir / 'reference_data.h5'\n",
    "\n",
    "# Detect compute resources\n",
    "device=config['device']\n",
    "num_cpus = os.cpu_count()\n",
    "has_gpu = torch.cuda.is_available()\n",
    "print(f\"Number of CPUs available and whether GPU computation is possible: \", num_cpus, has_gpu)\n",
    "    \n",
    "# Configure number of workers\n",
    "if has_gpu and device != \"cpu\":\n",
    "    # For GPU training, num_workers = num_cpus is often optimal\n",
    "    num_workers = num_cpus\n",
    "else:\n",
    "    # For CPU training, leave one core free for system processes\n",
    "    num_workers = max(1, num_cpus - 1)\n",
    "    \n",
    "# Create data loader\n",
    "dataloader, scalers = create_dataloader(\n",
    "    maldi_path=maldi_path,\n",
    "    ccf_path=coords_path,\n",
    "    ref_path=ref_path,\n",
    "    batch_size=config['batch_size'],\n",
    "    num_workers=num_workers,\n",
    "    device=config['device'],\n",
    "    downsample_factor=1,\n",
    "    chunk_size=500\n",
    ")\n",
    "\n",
    "# Get data dimensions\n",
    "sample_batch = next(iter(dataloader))\n",
    "n_spatial_points = sample_batch[0].size(1)\n",
    "coords_dim = sample_batch[1].size(1)\n",
    "\n",
    "logger.info(f\"Number of spatial points: {n_spatial_points}\")\n",
    "logger.info(f\"Coordinate dimensions: {coords_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialise Model\n",
    "\n",
    "Set up the c-VAE model and optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise model\n",
    "model = ConditionalVAE(\n",
    "    maldi_dim=n_spatial_points,\n",
    "    ccf_dim=coords_dim,\n",
    "    hidden_dim=config['hidden_dim'],\n",
    "    latent_dim=config['latent_dim'],\n",
    "    beta=config['beta'],\n",
    "    device=config['device']\n",
    ").to(config['device'])\n",
    "\n",
    "# Initialise optimizer with gradient clipping\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=config['learning_rate'],\n",
    "    epochs=config['epochs'],\n",
    "    steps_per_epoch=len(dataloader),\n",
    "    pct_start=0.1,  # Warm-up period\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "# Apply gradient clipping\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "\n",
    "Train the model while monitoring progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pasco/sdsc_mlibra/JupyterNotebooks/cleaned/brain_lipid_cvae_pcorso/models/cvae.py:161: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_mixed_precision and torch.cuda.is_available() else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mixed precision training disabled (not supported on CPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60: 100%|█| 15/15 [00:25<00:00,  1.72s/it, loss=0.2356, recon=0.2277, kl\n",
      "Epoch 2/60: 100%|█| 15/15 [00:26<00:00,  1.80s/it, loss=0.7003, recon=0.1261, kl\n",
      "Epoch 3/60: 100%|█| 15/15 [00:27<00:00,  1.80s/it, loss=1.6896, recon=0.0022, kl\n",
      "Epoch 4/60: 100%|█| 15/15 [00:27<00:00,  1.81s/it, loss=3.6516, recon=0.0024, kl\n",
      "Epoch 5/60: 100%|█| 15/15 [00:27<00:00,  1.82s/it, loss=6.2283, recon=0.0008, kl\n",
      "Epoch 6/60: 100%|█| 15/15 [00:27<00:00,  1.82s/it, loss=8.9549, recon=0.0003, kl\n",
      "Epoch 7/60: 100%|█| 15/15 [00:27<00:00,  1.81s/it, loss=11.8293, recon=0.0001, k\n",
      "Epoch 8/60: 100%|█| 15/15 [00:27<00:00,  1.82s/it, loss=14.6933, recon=0.0000, k\n",
      "Epoch 9/60: 100%|█| 15/15 [00:27<00:00,  1.82s/it, loss=17.4305, recon=0.0000, k\n",
      "Epoch 10/60: 100%|█| 15/15 [00:27<00:00,  1.83s/it, loss=19.9488, recon=0.0000, \n",
      "Epoch 11/60: 100%|█| 15/15 [00:27<00:00,  1.85s/it, loss=22.1645, recon=0.0000, \n",
      "Epoch 12/60: 100%|█| 15/15 [00:27<00:00,  1.84s/it, loss=24.0343, recon=0.0000, \n",
      "Epoch 13/60: 100%|█| 15/15 [00:27<00:00,  1.85s/it, loss=25.5139, recon=0.0000, \n",
      "Epoch 14/60: 100%|█| 15/15 [00:27<00:00,  1.86s/it, loss=26.5940, recon=0.0000, \n",
      "Epoch 15/60: 100%|█| 15/15 [00:28<00:00,  1.90s/it, loss=27.2629, recon=0.0000, \n",
      "Epoch 16/60: 100%|█| 15/15 [00:29<00:00,  1.95s/it, loss=27.5454, recon=0.0000, \n",
      "Epoch 17/60: 100%|█| 15/15 [00:28<00:00,  1.91s/it, loss=27.4577, recon=0.0000, \n",
      "Epoch 18/60: 100%|█| 15/15 [00:28<00:00,  1.91s/it, loss=27.0382, recon=0.0000, \n",
      "Epoch 19/60: 100%|█| 15/15 [00:27<00:00,  1.85s/it, loss=26.3225, recon=0.0000, \n",
      "Epoch 20/60: 100%|█| 15/15 [00:27<00:00,  1.82s/it, loss=25.3512, recon=0.0000, \n",
      "Epoch 21/60: 100%|█| 15/15 [00:27<00:00,  1.84s/it, loss=0.0052, recon=0.0000, k\n",
      "Epoch 22/60: 100%|█| 15/15 [00:27<00:00,  1.84s/it, loss=0.1510, recon=0.0000, k\n",
      "Epoch 23/60: 100%|█| 15/15 [00:27<00:00,  1.83s/it, loss=0.5831, recon=0.0000, k\n",
      "Epoch 24/60: 100%|█| 15/15 [00:27<00:00,  1.85s/it, loss=1.2900, recon=0.0000, k\n",
      "Epoch 25/60: 100%|█| 15/15 [00:27<00:00,  1.84s/it, loss=2.2513, recon=0.0000, k\n",
      "Epoch 26/60: 100%|█| 15/15 [00:27<00:00,  1.83s/it, loss=3.4357, recon=0.0000, k\n",
      "Epoch 27/60: 100%|█| 15/15 [00:27<00:00,  1.84s/it, loss=4.8022, recon=0.0000, k\n",
      "Epoch 28/60: 100%|█| 15/15 [00:28<00:00,  1.88s/it, loss=6.3015, recon=0.0000, k\n",
      "Epoch 29/60: 100%|█| 15/15 [00:28<00:00,  1.90s/it, loss=7.8777, recon=0.0000, k\n",
      "Epoch 30/60: 100%|█| 15/15 [00:30<00:00,  2.03s/it, loss=9.4718, recon=0.0000, k\n",
      "Epoch 31/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=11.0254, recon=0.0000, \n",
      "Epoch 32/60: 100%|█| 15/15 [00:29<00:00,  1.99s/it, loss=12.4848, recon=0.0000, \n",
      "Epoch 33/60: 100%|█| 15/15 [00:30<00:00,  2.02s/it, loss=13.8041, recon=0.0000, \n",
      "Epoch 34/60: 100%|█| 15/15 [00:29<00:00,  1.95s/it, loss=14.9481, recon=0.0000, \n",
      "Epoch 35/60: 100%|█| 15/15 [00:29<00:00,  2.00s/it, loss=15.8933, recon=0.0000, \n",
      "Epoch 36/60: 100%|█| 15/15 [00:30<00:00,  2.01s/it, loss=16.6270, recon=0.0000, \n",
      "Epoch 37/60: 100%|█| 15/15 [00:29<00:00,  1.98s/it, loss=17.1460, recon=0.0000, \n",
      "Epoch 38/60: 100%|█| 15/15 [00:30<00:00,  2.00s/it, loss=17.4539, recon=0.0000, \n",
      "Epoch 39/60: 100%|█| 15/15 [00:30<00:00,  2.01s/it, loss=17.5584, recon=0.0000, \n",
      "Epoch 40/60: 100%|█| 15/15 [00:30<00:00,  2.00s/it, loss=17.4698, recon=0.0000, \n",
      "Epoch 41/60: 100%|█| 15/15 [00:29<00:00,  1.98s/it, loss=0.0040, recon=0.0000, k\n",
      "Epoch 42/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=0.1086, recon=0.0000, k\n",
      "Epoch 43/60: 100%|█| 15/15 [00:29<00:00,  1.95s/it, loss=0.4189, recon=0.0000, k\n",
      "Epoch 44/60: 100%|█| 15/15 [00:29<00:00,  1.98s/it, loss=0.9267, recon=0.0000, k\n",
      "Epoch 45/60: 100%|█| 15/15 [00:29<00:00,  1.94s/it, loss=1.6195, recon=0.0000, k\n",
      "Epoch 46/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=2.4790, recon=0.0000, k\n",
      "Epoch 47/60: 100%|█| 15/15 [00:29<00:00,  1.97s/it, loss=3.4825, recon=0.0000, k\n",
      "Epoch 48/60: 100%|█| 15/15 [00:29<00:00,  1.98s/it, loss=4.6034, recon=0.0000, k\n",
      "Epoch 49/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=5.8122, recon=0.0000, k\n",
      "Epoch 50/60: 100%|█| 15/15 [00:29<00:00,  1.99s/it, loss=7.0780, recon=0.0000, k\n",
      "Epoch 51/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=8.3689, recon=0.0000, k\n",
      "Epoch 52/60: 100%|█| 15/15 [00:28<00:00,  1.93s/it, loss=9.6533, recon=0.0000, k\n",
      "Epoch 53/60: 100%|█| 15/15 [00:29<00:00,  1.97s/it, loss=10.9008, recon=0.0000, \n",
      "Epoch 54/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=12.0822, recon=0.0000, \n",
      "Epoch 55/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=13.1704, recon=0.0000, \n",
      "Epoch 56/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=14.1404, recon=0.0000, \n",
      "Epoch 57/60: 100%|█| 15/15 [00:29<00:00,  1.97s/it, loss=14.9694, recon=0.0000, \n",
      "Epoch 58/60: 100%|█| 15/15 [00:30<00:00,  2.06s/it, loss=15.6378, recon=0.0000, \n",
      "Epoch 59/60: 100%|█| 15/15 [00:30<00:00,  2.01s/it, loss=16.1289, recon=0.0000, \n",
      "Epoch 60/60: 100%|█| 15/15 [00:29<00:00,  1.96s/it, loss=16.4296, recon=0.0000, \n",
      "INFO:__main__:Training completed. Run ID: CVAE_b128_e60_z256_20250130_124426\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "metrics, avg_loss, run_id = model.train_model(\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=config['epochs'],\n",
    "    print_every=50,\n",
    "    use_mixed_precision=True,\n",
    "    scheduler=scheduler,\n",
    "    save_dir='checkpoints'\n",
    ")\n",
    "\n",
    "logger.info(f\"Training completed. Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Latent Space Analysis\n",
    "\n",
    "Analyse the learned latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualisation import LatentSpaceVisualizer\n",
    "\n",
    "# Initialize latent space visualizer\n",
    "latent_visualizer = LatentSpaceVisualizer()\n",
    "\n",
    "# Encode test data\n",
    "with torch.no_grad():\n",
    "    z_mu, z_logvar = model.encode(test_maldi, test_coords)\n",
    "\n",
    "# Plot latent space\n",
    "latent_visualizer.plot_latent_space_2d(\n",
    "    z=z_mu,\n",
    "    save_path='evaluation/latent_space.png'\n",
    ")\n",
    "\n",
    "# Plot latent traversal\n",
    "latent_visualizer.plot_latent_traversal(\n",
    "    decoder=model.decoder,\n",
    "    coordinates=test_coords[0:1],\n",
    "    dim=0,  # First latent dimension\n",
    "    save_path='evaluation/latent_traversal.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save configuration and metrics info\n",
    "\n",
    "Save the information on the training parameters and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dictionaries saved to checkpoints/CVAE_b128_e60_z256_20250130_124426/info_training.txt and training_plots\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Saving all dicts to the same file\n",
    "dict_save_dir = Path('checkpoints',run_id)\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(dict_save_dir, exist_ok=True)\n",
    "file_path = dict_save_dir / 'info_training.txt'\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "    f.write('\\n')\n",
    "    json.dump(config, f)\n",
    "    f.write('\\n')\n",
    "\n",
    "runID_path = Path('training_plots')\n",
    "os.makedirs(runID_path, exist_ok=True)\n",
    "runID_filepath = runID_path / 'runID.txt'\n",
    "with open(runID_filepath, 'w') as f:\n",
    "    json.dump(run_id, f)\n",
    "    f.write('\\n')\n",
    "\n",
    "logger.info(f\"Dictionaries saved to {file_path} and {runID_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training steps completed:\n",
    "1. ✓ Configure model hyperparameters\n",
    "2. ✓ Load preprocessed data\n",
    "3. ✓ Initialise model and optimiser\n",
    "4. ✓ Train and save the model\n",
    "5. ✓ Analyse the learned latent space\n",
    "6. ✓ Save model's configuration and losses\n",
    "\n",
    "The trained model is now ready for inference and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
